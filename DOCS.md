# Сам себе DevOps

Этот проект содержит небольшой RESTful API и минимальный набор контейнерфайлов для развертываения его в облаке. В качестве доп. заданий я добавил скрипты инициализации БД и кеширование 

## Ping API

API содержит 3 ручки: `/ping`, `/visits` и `/health`. При `GET` запросе по маршруту `/ping` пользователь получает HTTP ответ со сторокой `pong`, при `GET` запросе по маршруту `/visits` пользователь получает в качестве ответа число, отражающее колличество запросов `GET` к маршруту `/visits` от того же адреса, с которго был сделан запрос, маршрут `/health` нужен для проверки успешного запуска программы.

### Интаграции с внешней инфраструктурой 

#### PosgreSQL 

Для хранения статистики по колличествам запросов к маршруту `/ping`, используется СУБД PostgreSQL. Взаимодействие с API PostgreSQL происходит через библиотеку pgx

#### Redis

С целью уменьшения времени ответа на запросы я использую систему кеширования Redis

## Архитектура приложения

Приложение построено по слоистой архитектуре с четким разделением ответственности между компонентами

### Структура проекта

- `cmd/api` - точка входа в приложение, инициализация всех компонентов
- `internal/config` - загрузка конфигурации из переменных окружения
- `internal/domain` - доменные модели и интерфейсы
- `internal/handler` - HTTP обработчики запросов и маршрутизация
- `internal/middleware` - промежуточные обработчики (логирование, CORS)
- `internal/service` - бизнес-логика приложения
- `internal/repository` - слой работы с хранилищами данных (PostgreSQL, Redis)

Взаимодействие между слоями происходит сверху вниз: handler -> service -> repository. Каждый слой зависит только от интерфейсов, что обеспечивает слабую связность компонентов, весь код одного модуля находится в одноме месте, что обеспечивает высокую связанность (high coupling & low cohesion, все дела)

## Внешняя инфраструктура

Проект использует Docker для контейнеризации всех компонентов системы. Инфраструктура состоит из четырех основных сервисов:

### База данных

СУБД PostgreSQL используется для хранения статистики посещений. Схема базы данных содержит таблицу `visits` с полями:
- `id` - первичный ключ
- `ip` - IP-адрес клиента (уникальный)
- `count` - количество запросов от данного IP
- `created_at`, `updated_at` - временные метки

Данные хранятся в именованном Docker volume для сохранения между перезапусками контейнера

### Кеширование

Redis 7 используется как кеш для ускорения ответов на запросы. При обращении к `/visits` сначала проверяется наличие данных в Redis, и только при их отсутствии происходит запрос к PostgreSQL. Кеш автоматически инвалидируется при записи новых данных

### Миграции

Flyway 10 применяет миграции к базе данных при старте инфраструктуры. Миграционные скрипты находятся в директории `scripts/migration` и выполняются автоматически при запуске сервиса flyway. Контейнер с миграциями зависит от healthcheck базы данных и запускается только после успешной инициализации PostgreSQL

## Локальный запуск (контейнерезация инфраструктуры)

Для локальной разработки используется `docker-compose.local.yaml`, который поднимает только инфраструктурные зависимости (PostgreSQL, Redis, Flyway), а само приложение запускается на хост-машине

### Подготовка окружения

Создайте `.env` файл в корне проекта со следующими переменными:

```env
DB_HOST=localhost
DB_PORT=5432
DB_USER=user
DB_PASSWORD=password
DB_NAME=pingdb
DB_SSLMODE=disable

REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

SERVER_HOST=0.0.0.0
SERVER_PORT=8080
```

### Запуск зависимостей

```bash
docker compose -f ./deployments/docker-compose.local.yaml up -d
```

Эта команда запустит PostgreSQL, Redis и применит миграции через Flyway

### Сборка и запуск приложения

```bash
# Сборка исполняемого файла
make build

# Запуск приложения
make run
```

Команда `make build` компилирует приложение в директорию `bin/`, а `make run` запускает его напрямую через `go run`

### Проверка работы

```bash
curl http://localhost:5000/ping
# Ответ: pong

curl http://localhost:5000/visits
# Ответ: 1
```

### Остановка

```bash
docker compose -f ./deployments/docker-compose.local.yaml down
```

## Запуск в Docker (контейнерезация проекта целиком)

Для запуска полного стека приложения в контейнерах используется `docker-compose.yaml`

### Dockerfile

Сборка образа происходит в два этапа:

**Builder stage:**
- Базовый образ `golang:1.23-alpine`
- Установка зависимостей (`go mod download`)
- Компиляция статического бинарника с флагами `-ldflags="-w -s"` для уменьшения размера

**Main stage:**
- Минимальный образ `alpine:3.19`
- Создание непривилегированного пользователя `appuser`
- Копирование бинарника из builder stage
- Настройка healthcheck через `wget`

### Docker Compose

Файл `docker-compose.yaml` описывает все сервисы приложения и их взаимодействие

**Настройка сборки API:**
```yaml
api:
  build:
    context: ..
    dockerfile: build/dockerfile
    no_cache: true
    pull: true
```

Опция `no_cache: true` отключает использование кеша при сборке, гарантируя что изменения в коде всегда попадут в образ. Опция `pull: true` обновляет базовые образы перед сборкой

**Сети и зависимости:**

Все сервисы подключены к изолированной bridge-сети `app_network`. API сервис зависит от готовности базы данных

**Переменные окружения:**

API контейнер получает специальные переменные для связи между сервисами:
```yaml
environment:
  DB_HOST: db
  REDIS_HOST: cache
```

Внутри Docker сети сервисы обращаются друг к другу по именам сервисов, а не через localhost

**Volumes:**

PostgreSQL и Redis используют именованные volumes для персистентности данных:
```yaml
volumes:
  postgres_data:
    name: go_ping_api_postgres_data
  redis_data:
    name: go_ping_api_redis_data
```

### Запуск полного стека

```bash
cd deployments

# Сборка и запуск всех сервисов
docker compose up -d --build

# Просмотр логов
docker compose logs -f api

# Проверка статуса
docker compose ps
```

Флаг `--build` заставляет пересобрать образы перед запуском

### Проверка работы

```bash
curl http://localhost:5000/ping
curl http://localhost:5000/visits
```

### Остановка и очистка

```bash
# Остановка контейнеров
docker compose down

# Остановка с удалением volumes (удалит данные БД)
docker compose down -v

# Полная очистка
docker compose down -v --rmi all
```

## Makefile команды

Проект включает Makefile для упрощения рутинных операций:

```bash
make help          # Показать все доступные команды
make build         # Собрать бинарник
make run           # Запустить приложение локально
make test          # Запустить тесты
make clean         # Удалить артефакты сборки
make docker-build  # Собрать Docker образ
make docker-up     # Запустить все сервисы в Docker
make docker-down   # Остановить все сервисы
make migrate       # Применить миграции
```
